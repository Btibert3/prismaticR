ch = odbcConnect("R_DW", Sys.getenv("DW_USER"), Sys.getenv("DW_PASS"))
sqlColumns(ch, "BENTLEY.ZRVUREC")[3:5]
SQL = "SELECT ZRVUREC_PIDM,
COUNT DISTINCT (ZRVUREC_TERM_CODE) as count
FROM   BENTLEY.ZRVUREC
GROUP BY ZRVUREC_PIDM"
counts
counts = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
dim(counts)
counts
SQL = "SELECT ZRVUREC_PIDM,
COUNT (DISTINCT ZRVUREC_TERM_CODE) as count
FROM   BENTLEY.ZRVUREC
GROUP BY ZRVUREC_PIDM"
counts = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
dim(counts)
head(counts)
counts = subset(counts, COUNT == 1)
colnames(counts)
pidms = counts$ZRVUREC_PIDM
class(pidms)
head(pidms)
sqlColumns(ch, "BENTLEY.ZRVUREC")[3:5]
SQL = "SELECT  *
FROM    BENTLEY.ZRVUREC
WHERE   ZRVUREC_TERM_CODE = '201409' AND
ZRVUREC_RSTA_CODE = 'R' AND
ZRVUREC_STYP_CODE = 'F' AND
ZRVUREC_APP_IND = 'Y'"
recs = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
str(recs)
## get the data
SQL = "SELECT  *
FROM    BENTLEY.ZRVUREC
WHERE   ZRVUREC_TERM_CODE = '201309' AND
ZRVUREC_RSTA_CODE = 'R' AND
ZRVUREC_STYP_CODE = 'F' AND
ZRVUREC_APP_IND = 'Y'"
recs = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
dim(recs)
## get the data
SQL = "SELECT  *
FROM    BENTLEY.ZRVUREC
WHERE   ZRVUREC_TERM_CODE = '201409' AND
ZRVUREC_RSTA_CODE = 'R' AND
ZRVUREC_STYP_CODE = 'F' AND
ZRVUREC_APP_IND = 'N'"
recs = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
dim(recs)
recs = subset(recs, ZRVUREC_PIDM %in% pidms)
dim(recs)
table(recs$ZRVUREC_CTYP1_CCAT_CODE)
dataset
colnames(recs)
dataset = subset(recs,
select =c(ZRVUREC_ID,
ZRVUREC_FIRST_NAME,
ZRVUREC_LAST_NAME,
ZRVUREC_EMAIL))
names(dataset) = c("id", "firstname", "lastname", "email")
head(dataset)
help.start()
install.packages("ReportRs")
library(RODBC)
ch = odbcConnect("R_BANNER", Sys.getenv("BANNER_USER"), Sys.getenv("BANNER_PASS"))
SQL = "SELECT
DISTINCT SPRIDEN_PIDM
FROM   ZRVUREC, SPRIDEN, SRBRECR, GOREMAL
WHERE ZRVUREC_PIDM = SPRIDEN_PIDM and
ZRVUREC_PIDM = GOREMAL_PIDM and
ZRVUREC_PIDM = SRBRECR_PIDM and
ZRVUREC_TERM_CODE = SRBRECR_TERM_CODE and
ZRVUREC_TERM_CODE =:1 and
ZRVUREC_LEVL_CODE = 'UC' and
ZRVUREC_SESS_CODE='D' and
SRBRECR_RSTA_CODE = 'S' and
ZRVUREC_STYP_CODE = 'F' and
ZRVUREC_ADD_DATE >= '16-JAN-2014' and
ZRVUREC_ADD_DATE <= '24-FEB-2014' and
GOREMAL_PREFERRED_IND = 'Y' and
substr(ZRVUREC_CONTACT_STRING, 1, 3) IN ('PPN', 'SPN', 'APN','IPF') and
NOT EXISTS (SELECT 'x' FROM ZAVUUCD WHERE ZAVUUCD_PIDM = ZRVUREC_PIDM and
ZRVUREC_TERM_CODE= ZAVUUCD_TERM_CODE_ENTRY) and ZRVUREC_STYP_CODE = 'F' "
db
db = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
dim(db)
db
SQL = "SELECT
DISTINCT SPRIDEN_PIDM
FROM   ZRVUREC, SPRIDEN, SRBRECR, GOREMAL
WHERE ZRVUREC_PIDM = SPRIDEN_PIDM and
ZRVUREC_PIDM = GOREMAL_PIDM and
ZRVUREC_PIDM = SRBRECR_PIDM and
ZRVUREC_TERM_CODE = SRBRECR_TERM_CODE and
ZRVUREC_TERM_CODE = '201509' and
ZRVUREC_LEVL_CODE = 'UC' and
ZRVUREC_SESS_CODE='D' and
SRBRECR_RSTA_CODE = 'S' and
ZRVUREC_STYP_CODE = 'F' and
ZRVUREC_ADD_DATE >= '16-JAN-2014' and
ZRVUREC_ADD_DATE <= '24-FEB-2014' and
GOREMAL_PREFERRED_IND = 'Y' and
substr(ZRVUREC_CONTACT_STRING, 1, 3) IN ('PPN', 'SPN', 'APN','IPF') and
NOT EXISTS (SELECT 'x' FROM ZAVUUCD WHERE ZAVUUCD_PIDM = ZRVUREC_PIDM and
ZRVUREC_TERM_CODE= ZAVUUCD_TERM_CODE_ENTRY) and ZRVUREC_STYP_CODE = 'F' "
db = sqlQuery(ch, SQL, stringsAsFactors=F, as.is=T)
db
sqlColumns(ch, "ZRVUREC")[3:5]
load("C:/Users/btibert/Documents/Dropbox/Projects/cappex-crawl-mar14/parsed-datasets.Rdata")
library(RODBC)
ch = odbcConnect("R_DW", Sys.getenv("DW_USER"), Sys.getenv("DW_PASS"))
sqlTables(ch)
sqlTables(ch, "OWBTARGET")
sqlTables(ch, "OWBTARGET2")
sqlTables(ch, schema="OWBTARGET")
sqlTables(ch, schema="OWBTARGET2")
sqlTables(ch, schema="OWBTARGET")
library(XML)
library(plyr)
library(ggplot2)
library(reshape2)
URL = "http://www.hockey-reference.com/leagues/NHL_2014_skaters.html"
tables = readHTMLTable(URL, stringsAsFactors=F)
length(tables)
names(tables)
head(tables$stats)
nhl_14 = tables$stats
colnames(nhl_14) = tolower(colnames(nhl_14))
colnames(nhl_14)
nhl_14$rk = as.numeric(nhl_14$rk)
head(nhl_14)
head(nhl_14, 50)
nhl_14 = subset(nhl_14, !is.na(rk))
nhl_14 = subset(nhl_14, tm != 'Tm')
head(nhl_14, 50)
tail(nhl_14, 50)
tail(nhl_14, 75)
install.packages('devtools')
require(devtools)
install_github('shiny', 'rstudio')
require(shiny)
install_github('radiant','mostly-harmless')
runApp(system.file("marketing", package="radiant"))
library(RCurl)
library(XML)
PAGE = "http://www.payscale.com/college-roi/full-list"
raw_page = getURL(PAGE)
tbls = readHTMLTable(raw_page)
length(tbls)
tbls
tbl[2]
tbls[1]
tbls[[1]]
page_html = htmlParse(raw_page)
rm(tbls)
XPATH = '//*[@class="roi2014-group"]'
tbl = xpathSApply(page_html, XPATH)
names(tbl)
tbl[[1]]
tbl[[2]]
XPATH = '//*[@class="roi2014-results"]'
tbl = xpathSApply(page_html, XPATH)
length(tbl)
tbl[[1]]
devtools::install_github("d3Network", "christophergandrud")
library(d3Network)
load("~/Dropbox/Datasets/HigherEd/Cappex-March2014/parsed-datasets.Rdata")
head(network)
library(RCurl)
library(XML)
URL = "http://www.cappex.com/colleges/Bryant-University/admissions"
page = getURL(URL)
page_p = htmlParse(page)
names(page_p)
class(page_p)
tbls = readHTMLTable(page_p)
names(tbls)
tbls[[1]]
tbls[[2]]
tbls[[3]]
tbls[[4]]
tbls[[5]]
tbls[[2]]
tbls[[3]]
tbls = readHTMLTable(page_p, header==F)
tbls = readHTMLTable(page_p, header=FALSE)
tbls[[2]]
tbls[[3]]
tbls[[4]]
tbls[[5]]
library(d3Network)
load("~/Dropbox/Datasets/HigherEd/Cappex-August2013/edges-schools.Rdata")
ls()
head(edges)
dim(edges)
head(schools)
with(schools, hist(rating))
summary(schools$rating)
schools_f = subset(schools, rating >= 3.5)
dim(schools)
dim(schools_f)
head(edges)
edges_f = subset(edges, from %in% schools_f$unitid & to %in% schools_f$unitid)
dim(edges)
dim(edges_f)
head(schools_f)
head(edges_f)
d3ForceNetwork(Links=edges_f, Nodes=schools_f, Source="from", Target="to", Value="rank", NodeID="name")
?d3ForceNetwork
library(ReporteRs)
pptx_template = "~/Dropbox/Analytics/__TEMPLATES/Report Template 3.pptx"
doc = pptx( title = "title" )
names(doc)
doc[1]
doc[2]
dot[3]
doc[3]
doc[4]
slide.layouts(doc)
doc = addSlide( doc, slide.layout = "Title Slide" )
doc = addTitle( doc, "Presentation title" ) #set the main title
doc = addSubtitle( doc , "This document is generated with ReporteRs.")#set the sub-title
doc = addSlide( doc, slide.layout = "Two Content" )
doc = addTitle( doc, "Texts demo" ) #set the main title
texts = c( "Lorem ipsum dolor sit amet, consectetur adipiscing elit."
, "In sit amet ipsum tellus. Vivamus dignissim arcu sit amet faucibus auctor."
, "Quisque dictum tristique ligula."
)
# add simple text
doc = addParagraph( doc, value = texts)
library(XML)
library(RCurl)
Q =
Q
?format
QRY = sprintf("http://www.bing.com/search?q=undergrad+admission+twitter&first=%i", 0)
QRY
page = getURL(QRY)
doc = htmlParse(page)
links = unlist(doc['//@href'])
names(links) <- NULL
View(links)
library(stringr)
twitter_links = links[str_detect(links, "twitter.com")]
twitter_liks = unique(twitter_links)
twitter_links = unique(twitter_links)
twitter_links
library(d3Network)
Source <- c("A", "A", "A", "A", "B", "B", "C", "C", "D")
Target <- c("B", "C", "D", "J", "E", "F", "G", "H", "I")
NetworkData <- data.frame(Source, Target)
d3SimpleNetwork(NetworkData, width = 400, height = 250)
d3ForceNetwork
DDIR = "~/Dropbox/Analytics/DW/data"
list.files(DDIR)
apps = readRDS(file.path(DDIR, "uadm.rds"))
cont = readRDS(file.path(DDIR, "cont.rds"))
apps = subset(apps, term = '201409')
apps = subset(apps, term == '201409')
head(cont)
cont_a = subset(cont, pidm %in% apps$pidm)
head(cont_a)
devtools::install_github("rstudio/rticles")
install.packages("installr")
install.packages("installr")
install.packages("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
?create
library(devtools)
?create
create("contactR")
library(roxygen2)
library(streamR)
system("python /Users/brock/Desktop/test-rstudio-python.py")
system("python /Users/brock/Desktop/test-rstudio-python.py")
install.packages("SocialMediaMineR")
library(SocialMediaMineR)
tmp = get_facebook("http://www.bentley.edu/undergraduate")
tmp
get_facebook
###############################################################################
## Roll up the performance for search emails
###############################################################################
## load the packages
library(stringr)
library(plyr)
## bring in the datasets
DDIR = "~/Dropbox/Analytics/DW/data"
comm = readRDS(file.path(DDIR, "comm-raw.rds"))
open = readRDS(file.path(DDIR, "open-raw.rds"))
## keep only search emails
search = subset(comm, str_detect(tolower(refdesc), "search"))
search = subset(comm, str_detect(refdesc, "OS_MKT_201509_Search"))
search = subset(search, !str_detect(refdesc, "Seed"))
tmp = ddply(search, .(refdesc), summarise, num = length(pidm))
tmp = subset(tmp, num > 100)
search = subset(search, refdesc %in% tmp$refdesc)
rm(tmp)
## keep only the summary data that makes sense
links = subset(open, msgid %in% search$msgid)
## use plyr to roll up the stats
stats = ddply(links, .(msgid), summarise,
open = 1,
click = max(ifelse(type == 'LINK', 1, 0)))
## add back on to the search data -- left join to retain non-engagement
search_perf = merge(search, stats, all.x=T)
search_perf$open[is.na(search_perf$open)] = 0
tmp = search_perf[1:5, ]
tmp
transform(tmp, wave = str_extract(refdesc, 'W[1-9]{1}'))
transform(tmp, wave = str_extract(refdesc, 'W[1-9]{1}'), email = str_extract(refdesc, 'E[1-10]'))
search_perf = transform(search_perf,
wave = str_extract(refdesc, 'W[1-9]{1}'),
email = str_extract(refdesc, 'E[1-10]'))
head(search_perf)
with(search_perf, table(wave))
with(search_perf, table(email))
tail(search_perf)
search_perf = transform(search_perf,
wave = str_extract(refdesc, 'W[1-9]{1}'),
email = str_extract(refdesc, 'E[0-9]{1,2}'))
with(search_perf, table(wave))
with(search_perf, table(email))
ls()
perf
head(search_perf)
perf = ddply(search_perf, (wave, email), mutate,
deliv = sum(delivflag),
open = sum(open),
click = sum(click, na.rm=T),
open_rate = open / deliv,
click_rate = click / open)
perf = ddply(search_perf, (wave, email), summarise,
deliv = sum(delivflag),
open = sum(open),
click = sum(click, na.rm=T),
open_rate = sum(open) / sum(delivflag),
click_rate = sum(click, na.rm=T) / sum(open))
perf = ddply(search_perf, .(wave, email), summarise,
deliv = sum(delivflag),
open = sum(open),
click = sum(click, na.rm=T),
open_rate = sum(open) / sum(delivflag),
click_rate = sum(click, na.rm=T) / sum(open))
str(search_perf)
perf = ddply(search_perf, .(wave, email), summarise,
deliv = sum(as.numeric(delivflag)),
open = sum(open),
click = sum(click, na.rm=T),
open_rate = sum(open) / sum(as.numeric(delivflag)),
click_rate = sum(click, na.rm=T) / sum(open))
head(perf)
perf = transform(perf, email = gsub("E", "", email))
head(perf)
perf = arrange(perf, wave, email)
View(perf)
head(perf)
perf = ddply(search_perf, .(wave, email), summarise,
deliv = sum(as.numeric(delivflag)),
open = sum(open),
click = sum(click, na.rm=T),
open_rate = sum(open) / sum(as.numeric(delivflag)),
click_rate = sum(click, na.rm=T) / sum(open))
perf = transform(perf, email = as.numeric(gsub("E", "", email)))
perf = arrange(perf, wave, email)
head(perf)
View(perf)
perf
sum(perf$click)
library(RNeo4j)
?clear
graph = startGraph("http://10.0.0.3:7474/db/data/")
library(RCurl)
library(rjson)
URL = "https://raw.githubusercontent.com/christophergandrud/networkD3/master/JSONdata/energy.json"
raw_dat = getURL(URL)
raw_j = toJSON(raw_dat)
names(raw_j)
length(raw_j)
raw_j
devtools::install_github("christophergandrud/networkD3")
library(networkD3)
library(networkD3)
EngLinks <- JSONtoDF(jsonStr = Energy, array = "links")
URL <- "https://raw.githubusercontent.com/christophergandrud/d3Network/sankey/JSONdata/energy.json"
Energy <- getURL(URL, ssl.verifypeer = FALSE)
# Convert to data frame
EngLinks <- JSONtoDF(jsonStr = Energy, array = "links")
EngNodes <- JSONtoDF(jsonStr = Energy, array = "nodes")
raw_j = fromJSON(raw_dat)
names(raw_j)
links <- JSONtoDF(jsonStr = Energy, array = "links")
nodes <- JSONtoDF(jsonStr = Energy, array = "nodes")
head(links)
head(nodes)
d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
library(networkD3)
d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
nodes <- JSONtoDF(jsonStr = Energy, array = "nodes")
sankeyNetwork(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
?JSONtoDF
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
create("prismaticR")
setwd("~/Dropbox/Projects/prismaticR")
library(httr)
library(RCurl)
source('~/Dropbox/Projects/prismaticR/R/prizURL.R', echo=TRUE)
TOKEN = "MTQyMzQwOTM4MzUxOA.cHJvZA.YnRpYmVydDNAZ21haWwuY29t.Vz2n7Zd1ks8UZ4j9fDpU3MWVogk"
prizAPI(TOKEN, "http://www.bentley.edu/about/mission-vision-and-values")
prizURL(TOKEN, "http://www.bentley.edu/about/mission-vision-and-values")
rm(prizUrl)
source('~/Dropbox/Projects/prismaticR/R/prizURL.R', echo=TRUE)
prizURL(TOKEN, "http://www.bentley.edu/about/mission-vision-and-values")
EP = "http://interest-graph.getprismatic.com/url/topic"
EP = "http://interest-graph.getprismatic.com/url/topic"
URL = "http://www.bentley.edu/about/mission-vision-and-values"
req = POST(EP,
query = list(url = RCurl::curlEscape(URL)),
config(httpheader = c("X-API-TOKEN" = TOKEN)))
req$status_code
req$content
content(req)
req = GET(EP, query = list(url = RCurl::curlEscape(URL),
api-token = TOKEN))
req = GET(EP, query = list(url = RCurl::curlEscape(URL),
`api-token` = TOKEN))
req$status_code
content(req)
req = GET(EP, query = list(url = RCurl::curlEscape(URL),
`api-token` = TOKEN))
content(req)
Q = "hockey"
EP = "http://interest-graph.getprismatic.com/topic/?search-query="
## make sure the token exsists
if (is.na(TOKEN)) {
message("You must supply a valid token")
}
## make sure query exists
if (is.na(Q)) {
message("You must supply a valid URL in the form of http://....")
}
## build the url
PAGE = paste(EP,
RCurl::curlEscape(Q),
"&api-token="
TOKEN,
PAGE = paste(EP,
RCurl::curlEscape(Q),
"&api-token=",
TOKEN,
sep = "")
PAGE
PAGE = paste(EP,
Q,
"&api-token=",
TOKEN,
sep = "")
PAGE
TEXT = "Chicago White Sox ace Chris Sale suffered a foot injury in an accident at his home and will miss at least three weeks of preparation time for the regular season. Sale suffered an avulsion fracture to the lateral side of his right foot Friday at his spring training residence in Arizona, but the pitcher declined to reveal how the injury happened. White Sox general manager Rick Hahn said Sale landed “awkwardly when he got off the back of his truck,” while unloading items."
PAGE = paste(EP,
"?api-token=",
TOKEN,
"&title=title",
"&text=",
RCurl::curlEscape(TEXT),
sep = "")
PAGE
PAGE
x = POST(EP, body=list(`api-token`=TOKEN, title="title", body=TEXT))
x$status_code
PAGE = paste(EP,
"?api-token=",
TOKEN,
"&title=title",
"&body=",
TEXT,
sep = "")
resp = httr::GET(PAGE)
resp$status_code
TID = 1950
EP = "http://interest-graph.getprismatic.com/topic/topic"
PAGE = paste(EP,
"?api-token=",
TOKEN,
"&id=",
TID,
sep = "")
PAGE
resp = httr::GET(PAGE)
resp$status_code
content(resp)
dat = content(resp)
df = do.call(rbind, lapply(dat$topics, function(x) data.frame(topic_id = x$id,
topic = x$topic,
score = x$score,
stringsAsFactors=F)))
df
source('~/Dropbox/Projects/prismaticR/R/prizSIM.R', echo=TRUE)
prizSIM(TOKEN, 1950)
prizURL(TOKEN, "https://en.wikipedia.org/wiki/New_England_Patriots")
document()
document()
document()
